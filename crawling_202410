from apify_client import ApifyClient
import requests
from bs4 import BeautifulSoup

# Apifyクライアントの初期化
client = ApifyClient('your-apify-token')  # ApifyのAPIトークンを入力

# スクレイピング対象のURL
url = 'https://itp.ne.jp/keyword?area=13&areaword=%E6%9D%B1%E4%BA%AC%E9%83%BD&keyword=%E8%BE%B2%E6%A5%AD&sbmap=false&sort=01'

def scrape_data(url):
    # ページの内容を取得
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')

    # 企業名と電話番号の抽出
    companies = []
    
    # 企業名を含む<a>タグを探す
    for link in soup.find_all('a', href=True):
        if 'info' in link['href']:  # href属性に"info"が含まれているものをフィルタリング
            name = link.text.strip()  # 企業名の取得
            
            # 対応する電話番号の取得
            phone_element = link.find_next('span', class_='wixui-rich-text__text')
            phone = phone_element.text.strip() if phone_element else 'N/A'
            
            companies.append({'name': name, 'phone': phone})
    
    return companies

# Apify上でActorの作成
def create_actor():
    # 収集データのリクエスト
    actor_input = {
        "startUrls": [{"url": url}]
    }

    # Actorを起動し、結果を取得
    run = client.actor('apify/web-scraper').call(actor_input)
    
    # 結果を表示
    dataset_id = run['defaultDatasetId']
    items = client.dataset(dataset_id).list_items().items
    return items

if __name__ == "__main__":
    scraped_data = scrape_data(url)
    for company in scraped_data:
        print(f"Company Name: {company['name']}, Phone: {company['phone']}")
    
    # Actorで実行した場合
    actor_data = create_actor()
    print(actor_data)
